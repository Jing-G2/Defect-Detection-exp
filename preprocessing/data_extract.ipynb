{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU-CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patoolib\n",
    "patoolib.extract_archive(\"/nfs4-p1/gj/datasets/NEU surface defect database.rar\", outdir=\"/nfs4-p1/gj/datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import seaborn\n",
    "\n",
    "np.random.seed(928)\n",
    "torch.manual_seed(928)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "datasets_root = \"/nfs4-p1/gj/datasets/\"\n",
    "dataset_name = \"NEU-CLS\"\n",
    "graph_data_root = \"/nfs4-p1/gj/DEFECT2022/data/\"\n",
    "\n",
    "class_names = [\"RS\",\"In\",\"Pa\",\"Sc\",\"PS\",\"Cr\"]\n",
    "image_size = 200 # hight = width\n",
    "class_num = 300 # 300 images in one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = plt.imread(datasets_root + dataset_name+\"/Cr_1.bmp\")\n",
    "print(type(sample))\n",
    "print(sample.shape)\n",
    "print(sample.size)\n",
    "print(sample.max())\n",
    "print(sample.min())\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_size = 10\n",
    "color_unit_size = 16\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sample = sample // color_unit_size\n",
    "print(sample.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "patch_x_max = int(image_size/unit_size)\n",
    "patch_y_max = patch_x_max\n",
    "\n",
    "for i in range(patch_x_max):\n",
    "    for j in range(patch_y_max):\n",
    "        patch = sample[i * unit_size: (i + 1) * unit_size, j * unit_size: (j + 1) * unit_size]\n",
    "        uni_c, counts = np.unique(patch, return_counts=True)\n",
    "        \n",
    "        for c, count in zip(uni_c, counts):\n",
    "            cur_node = dict()\n",
    "            cur_node['i'] = np.array(i)\n",
    "            cur_node['j'] = np.array(j)\n",
    "            cur_node['c'] = np.array(c)\n",
    "            cur_node['density'] = count / patch.size\n",
    "\n",
    "            nodes.append(cur_node)\n",
    "            \n",
    "# print(len(nodes))\n",
    "nodesframe = pd.DataFrame(nodes)\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "# print(nodesframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesframe.to_csv(graph_data_root+dataset_name+\"/nodes.csv\", index_label='node_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "print(nodesframe.shape)\n",
    "\n",
    "for node_index in range(nodesframe.shape[1]):\n",
    "    node = nodesframe.iloc[node_index]\n",
    "    # print(node)\n",
    "    adj_nodes = nodesframe.loc[(nodesframe['i']>=node['i']-1)&(nodesframe['i']<=node['i']+1)&\n",
    "                           (nodesframe['j']>=node['j']-1)&(nodesframe['j']<=node['j']+1)&\n",
    "                           (nodesframe['c']>=node['c']-1)&(nodesframe['c']<=node['c']+1)]\n",
    "    # print(adj_nodes)\n",
    "    for adj_nodes_index in adj_nodes.index:\n",
    "        # print(adj_nodes_index)\n",
    "        if adj_nodes_index != node_index:\n",
    "            cur_edge = dict()\n",
    "            cur_edge['from_node'] = node_index\n",
    "            cur_edge['to_node'] = adj_nodes_index\n",
    "\n",
    "            edges.append(cur_edge)\n",
    "\n",
    "# print(len(edges))\n",
    "edgesframe = pd.DataFrame(edges)\n",
    "# print(edgesframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesframe.to_csv(graph_data_root+dataset_name+\"/edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "datasets_root = \"/nfs4-p1/gj/datasets/AnomalyDetection/\"\n",
    "graph_data_root = \"/nfs4-p1/gj/DEFECT2022/data/\"\n",
    "\n",
    "dataset_name = \"KSDD\"\n",
    "dir_names = os.listdir(os.path.join(datasets_root, dataset_name))\n",
    "print(len(dir_names))\n",
    "unit_size = 50\n",
    "color_unit_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: (1260, 500)\n",
      "img.max: 255\n",
      "label.max: 255\n",
      "26 10\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "\n",
    "label_list = glob.glob(\n",
    "    os.path.join(datasets_root, dataset_name, dir_names[0], f'*.bmp'))\n",
    "img_list = glob.glob(\n",
    "    os.path.join(datasets_root, dataset_name, dir_names[0], f'*.jpg'))\n",
    "\n",
    "label = plt.imread(\n",
    "    os.path.join(datasets_root, dataset_name, dir_names[0], label_list[1]))\n",
    "img = plt.imread(\n",
    "    os.path.join(datasets_root, dataset_name, dir_names[0], img_list[1]))\n",
    "\n",
    "label = plt.imread('/nfs4-p1/gj/datasets/AnomalyDetection/KSDD/kos02/Part6_label.bmp')\n",
    "img = plt.imread('/nfs4-p1/gj/datasets/AnomalyDetection/KSDD/kos02/Part6.jpg')\n",
    "print('img.shape:', img.shape)\n",
    "print('img.max:', img.max())\n",
    "print('label.max:', label.max())\n",
    "height, width = img.shape[0], img.shape[1]\n",
    "img = img // color_unit_size\n",
    "\n",
    "patch_x_max = ceil(height / unit_size)\n",
    "patch_y_max = ceil(width / unit_size)\n",
    "print(patch_x_max, patch_y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(label.max())\n",
    "print(label.min())\n",
    "print(label.max()== label.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "class_index = 0 if label.max() == label.min() else 1\n",
    "print(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "# divide the whole image into several patch\n",
    "for i in range(patch_x_max):\n",
    "    for j in range(patch_y_max):\n",
    "        if (i + 1) * unit_size < height and (j + 1) * unit_size < width:\n",
    "            patch = img[i * unit_size:(i + 1) * unit_size,\n",
    "                        j * unit_size:(j + 1) * unit_size]\n",
    "        elif (i + 1) * unit_size >= height and (j + 1) * unit_size < width:\n",
    "            patch = img[i * unit_size:, j * unit_size:(j + 1) * unit_size]\n",
    "        elif (i + 1) * unit_size < height and (j + 1) * unit_size >= width:\n",
    "            patch = img[i * unit_size:(i + 1) * unit_size, j * unit_size:]\n",
    "        elif (i + 1) * unit_size >= height and (j +\n",
    "                                                1) * unit_size >= width:\n",
    "            patch = img[i * unit_size:, j * unit_size:]\n",
    "\n",
    "        uni_c, counts = np.unique(patch, return_counts=True)\n",
    "\n",
    "        # define each patch as a node in the graph\n",
    "        for c, count in zip(uni_c, counts):\n",
    "            cur_node = dict()\n",
    "            cur_node['i'] = np.array(i)\n",
    "            cur_node['j'] = np.array(j)\n",
    "            cur_node['c'] = np.array(c)\n",
    "            cur_node[\n",
    "                'density'] = count * unit_size * unit_size / patch.size\n",
    "\n",
    "            nodes.append(cur_node)\n",
    "\n",
    "nodesframe = pd.DataFrame(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesframe.to_csv('/nfs4-p1/gj/DEFECT2022/data/node.csv',\n",
    "                  index_label='node_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "# for node_index in range(nodesframe.shape[0]):\n",
    "#     node = nodesframe.iloc[node_index]\n",
    "#     adj_nodes = nodesframe.loc[(nodesframe['i'] >= node['i'] - 1)\n",
    "#                                 & (nodesframe['i'] <= node['i'] + 1) &\n",
    "#                                 (nodesframe['j'] >= node['j'] - 1) &\n",
    "#                                 (nodesframe['j'] <= node['j'] + 1) &\n",
    "#                                 (nodesframe['c'] >= node['c'] - 1) &\n",
    "#                                 (nodesframe['c'] <= node['c'] + 1)]\n",
    "#     if len(adj_nodes) > 27:\n",
    "#         print(adj_nodes.shape)\n",
    "#         print(node)\n",
    "#         print(len(node))\n",
    "#         print(adj_nodes)\n",
    "#         break\n",
    "#     for adj_nodes_index in adj_nodes.index:\n",
    "#         if adj_nodes_index != node_index:\n",
    "#             cur_edge = dict()\n",
    "#             cur_edge['from_node'] = node_index\n",
    "#             cur_edge['to_node'] = adj_nodes_index\n",
    "\n",
    "#             edges.append(cur_edge)\n",
    "\n",
    "# edgesframe = pd.DataFrame(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names ['Normal', 'Anomalous']\n",
      "Normal #graph: 347\n",
      "Anomalous #graph: 52\n",
      "dataset len: 239 79 81\n",
      "dataset len: 416 79 81\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9f028939ca116a935059bed3c1ea06cf9f7a9792586a840ded62574db30fb70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
